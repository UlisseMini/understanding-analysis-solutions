\section{Taylor Series}

\begin{exercise}
  The derivation in Example 6.6.1 shows the Taylor series for $\arctan (x)$ is valid for all $x \in(-1,1)$. Notice, however, that the series also converges when $x=1$. Assuming that $\arctan(x)$ is continuous, explain why the value of the series at $x=1$ must necessarily be $\arctan(1)$. What interesting identity do we get in this case?

\end{exercise}
\begin{solution}
  Abel's theorem (Theorem 6.5.4) implies the series converges uniformly on $[0, 1]$.
  Combined with (Theorem 6.2.6) we see function the series converges to must be continuous.
  Taking limits shows this value must be $\arctan(1)$ giving the identity
  $$
  \arctan(1) = \frac{\pi}{4} = 1 - \frac 13 + \frac 15 - \frac 17 + \dots
  $$
\end{solution}
\begin{exercise}
  Starting from one of the previously generated series in this section, use manipulations similar to those in Example 6.6.1 to find Taylor series representations for each of the following functions. For precisely what values of $x$ is each series representation valid?
  \enum {
  \item $x \cos \left(x^{2}\right)$
  \item $x /\left(1+4 x^{2}\right)^{2}$
  \item $\log \left(1+x^{2}\right)$
  }
\end{exercise}
\begin{solution}
  \enum {
  \item We know $\cos(x) = 1 - x^2/2 + x^4/4! - \dots$ on all of $\mathbf{R}$ so
    $$
    x\cos(x^2)
    = x - \frac{x^5}{2!} + \frac{x^9}{4!} - \frac{x^{13}}{6!} + \dots
    = \sum_{n=0}^\infty (-1)^n \frac{x^{4n+1}}{(2n)!}
    $$
  \item
    Since
    $$
    \frac{x}{(1+4x^2)^2} = \frac{\mathrm d}{\mathrm dx}\, \frac{- 1/8}{1 + 4x^2}
    $$
    We can use the geometric series then differentiate
    $$
    \frac{-1/8}{1 - (-4x^2)} = (-1/8)\sum_{n=0}^\infty (-4x^2)^n = \sum_{n=0}^\infty \frac{(-1)^{n+1} (4x^2)^n}{8}
    $$
    Is valid when $|4x^2|<1$ or $|x| < 1/2$, differentiating gives
    $$
    \frac{x}{(1 - 4x^2)^2}
    \stackrel{?}{=} \sum_{n=0}^\infty \frac{(-1)^{n+1} 8x\cdot n(4x^2)^{n-1}}{8}
    = \sum_{n=0}^\infty (-1)^{n+1} xn(4x^2)^{n-1}
    $$
    Every $|x|<1/2$ converges by the ratio test, meaning the right-hand series converges for all $x \in (-1/2,1/2)$.
    Checking endpoints $x=1/2$ gives $\sum (-1)^{n+1}n/2$ which clearly doesn't converge, similarly $x=-1/2$ doesn't converge.

    Finally, we must show our differentiated series converges to the right thing. Let $f_m = \sum_{n=0}^m (-1)^{n+1}xn(4^2)^{n-1}$ and $f(x) = x/{(1+4x^2)}$. We have $(f_m') \to f'$ uniformly (by construction via geometric series), and since $(f_m)$ and $f$ agree at $x=0$ ($f_m(0) \to 0$ and $f(0) = 0$) we must have $(f_m) \to f$ uniformly.
  \item
    We know the Taylor series for $\log(1 + x)$ is
    $$
    \log(1 + x) = x - \frac 12 x^2 + \frac 13 x^3 - \dots = \sum_{n=1}^\infty \frac {(-1)^n x^n}{n}
    $$
    Which converges on $(-1, 1]$. Substituting $x^2$ for $x$ gives
    $$
    \log(1 + x^2) = \sum_{n=1}^\infty \frac{(-1)^n x^{2n}}{n}
    $$
    Which converges on $[0, 1]$.
  }
\end{solution}
\begin{exercise}
  Derive the formula for the Taylor coefficients given in Theorem 6.6.2.

\end{exercise}
\begin{solution}
  We are given $f(x) = \sum_{n=0}^\infty a_nx^n$ defined on some nontrivial interval $(-R,R)$. $a_0 = f(0)$ by definition, now applying Theorem 6.5.7 we get
  $$
  f'(x) = \sum_{n=1}^\infty a_nnx^{n-1}
  $$
  and $f'(0) = a_1\cdot 1$ by definition of $f'$, continue like this applying 6.5.7 each time to get
  $$
  a_n = \frac{f^{(n)}(0)}{n!}
  $$
\end{solution}
\begin{exercise}
  Explain how Lagrange's Remainder Theorem can be modified to prove
  $$
  1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\frac{1}{5}-\frac{1}{6}+\cdots=\log (2)
  $$
\end{exercise}
\begin{solution}
  Let \(E_N(x) = \log(1+x) - \sum_{n=1}^\infty \frac {(-1)^n x^n}{n}\).
  The proof presented of Lagrange's Remainder Theorem assumed that \(x > 0\) to simplify notation, and found a value of \(c \in (0, x)\), with the proof for \(x < 0\) being implicit. But we can just ignore \(x < 0\) to state that given \(x \in (0, R)\) there exists \(0 < c < x\) satisfying
  \[E_N(x) = \frac{f^{(N+1)}(c)}{(N+1)!}x^{N+1}\]
Now, \(\abs{f^{(N+1)}(c)} = N!(1+c)^{-(N+1)}\), so for \(c < x = 1\) we have
\[\abs{E_N(x)} \leq \frac{1}{N+1}\]
which converges to 0 as \(N \to \infty\). Hence the Taylor series is equal to \(\log(1+x)\) over at least \((0,1)\), and we can extend this equality to \((0, 1]\) since both \(\log(1+x)\) and the Taylor series are continuous at 1 (we established the latter in Exercise 6.5.1). Plugging \(x = 1\) into both equations leaves us with the desired equality.
\end{solution}

\begin{exercise}

  \enum {
  \item Generate the Taylor coefficients for the exponential function $f(x)=e^{x}$, and then prove that the corresponding Taylor series converges uniformly to $e^{x}$ on any interval of the form $[-R, R]$.
  \item Verify the formula $f^{\prime}(x)=e^{x}$.
  \item Use a substitution to generate the series for $e^{-x}$, and then informally calculate $e^{x} \cdot e^{-x}$ by multiplying together the two series and collecting common powers of $x$.
  }
\end{exercise}
\begin{solution}
  \enum{
  \item $f(x) = e^{x} = \sum_{n=0}^\infty x^n/n!$ from $f^{(n)}(0) = 1$
  \item Differentiating the series is valid by Theorem 6.5.7
    $$f'(x) = \sum_{n=1}^\infty \frac{nx^{n-1}}{n!} = \sum_{n=1}^\infty \frac{x^{n-1}}{(n-1)!} = \sum_{n=0}^\infty \frac{x^n}{n!}$$
  \item Let \(a_n = (-1)^n/n!\), \(b_n = 1/n!\), and \(d_n = \sum^{n}_{k=0} a_k b_{n-k}\); the informal power series representation of \(e^x \cdot e^{-x}\) becomes \(\sum^\infty_{n=0} d_n x^n\). By plugging in \(0\) we have \(d_0 = 0\). For \(n > 0\), note that

  \[(n!)d_n = \sum^n_{k=0}\frac{n!}{k! (n-k)!} (-1)^k = \sum^n_{k=0} {n \choose k} (-1)^k = \sum^n_{k=0,\ k \text{ even}} {n \choose k} - \sum^n_{k=0,\ k \text{ odd}} {n \choose k} \]
  The first term is the total number of ways to choose an even number of elements from a set of size \(n\), while the second term is the number of ways to choose an odd number of elements. For \(n\) odd, these two terms must be equal, since for every unique subset with an even number of elements, we get a unique subset with an odd number of elements by taking the set complement. Hence for \(n\) odd we must have \(d_n = 0\).

  It takes a bit more work for \(n\) even. Call this set \(N\) and divide it into disjoint subsets \(A\) containing the first \(n-1\) elements and \(B\) containing the remaining element. Let \(P \choose \text{even}\) be the number of ways to choose an even number of elements from \(P\) and \(P \choose \text{odd}\) be defined similarly. Then
  \[{N \choose \text{odd}} = {A \choose \text{odd}}{B \choose \text{even}} + {A \choose \text{even}}{B \choose \text{odd}} = {A \choose \text{odd}} + {A \choose \text{even}}\]
  while
  \[{N \choose \text{even}} = {A \choose \text{even}}{B \choose \text{even}} + {A \choose \text{odd}}{B \choose \text{odd}} = {A \choose \text{even}} + {A \choose \text{odd}} = {N \choose \text{odd}}\]
  and we once again have \(d_n = 0\). (Incidentally, this trick does not work for \(n = 0\) since it relies on being able to remove an element from \(N\) to form \(A\).)

  Putting everything together we have \(e^x \cdot e^{-x} = 1\) as expected.
  }
\end{solution}

\begin{exercise}
  Review the proof that $g^{\prime}(0)=0$ for the function
  $$
  g(x)= \begin{cases}e^{-1 / x^{2}} & \text { for } x \neq 0 \\ 0 & \text { for } x=0\end{cases}
  $$
  introduced at the end of this section.
  \enum {
  \item Compute $g^{\prime}(x)$ for $x \neq 0$. Then use the definition of the derivative to find $g^{\prime \prime}(0)$.
  \item Compute $g^{\prime \prime}(x)$ and $g^{\prime \prime \prime}(x)$ for $x \neq 0$. Use these observations and invent whatever notation is needed to give a general description for the $n$th derivative $g^{(n)}(x)$ at points different from zero.
  \item Construct a general argument for why $g^{(n)}(0)=0$ for all $n \in \mathbf{N}$.
  }
\end{exercise}
\begin{solution}
\enum{
    \item \(g'(x) = 2x^{-3} e^{-x^{-2}}\). Repeatedly using L'Hospital's Rule,
    \[ g''(0) = \lim_{x \to 0} \frac{2x^{-3} e^{-x^{-2}}}{x} = \lim_{x \to 0}\frac{2x^{-4}}{e^{1/x^2}} = 2 \lim_{x \to 0} \frac{-4x^{-5} x^3}{-2e^{1/x^2}} =4 \lim_{x \to 0} \frac{-2x^{-3} x^3}{-2e^{1/x^2}}=  0 \]
    \item Explicitly computing things sounds rather tedious, so let's skip to the general form. We claim that \(g^{(n)}(x)\) for \(x \neq 0\) is of the form \(P_n(x) e^{-1/x^2}\) where \(P_n(x)\) is some polynomial in \(x^{-1}\). We can prove this inductively, by noting \(g^{(n+1)}(x) = [P_n'(x) + P_n(x) (-2x^{-3})] e^{-1/x^2}\). Differentiating a polynomial in \(x^{-1}\) with respect to \(x\) only increases the powers, and polynomials are closed under addition and multiplication, so clearly the term in square brackets continues to be a polynomial in \(x^{-1}\).
    \item Let \(P_n(x) = \sum a_n x^{-b_n}\) with \(a_n\) constant and \(b_n \geq 0\). We'll compute the formula for the derivative termwise, and use induction.
    \[\lim_{x \to 0} \frac{a_n x^{-b_n} e^{-1/x^2}}{x} = a_n \lim_{x \to 0} \frac{x^{-(b_n + 1)}}{e^{1/x^2}}\]
    It's easy to show that this is equal to 0, since every time we apply L'Hospital's rule, the denominator doesn't change (and continues to go to infinity) while the exponent in the numerator increases by 2 each time, eventually becoming non-negative and preventing the numerator from also going to infinity.
}
\end{solution}

\begin{exercise}
  Find an example of each of the following or explain why no such function exists.
  \enum {
  \item An infinitely differentiable function $g(x)$ on all of $\mathbf{R}$ with a Taylor series that converges to $g(x)$ only for $x \in(-1,1)$.
  \item An infinitely differentiable function $h(x)$ with the same Taylor series as $\sin (x)$ but such that $h(x) \neq \sin (x)$ for all $x \neq 0$.
  \item An infinitely differentiable function $f(x)$ on all of $\mathbf{R}$ with a Taylor series that converges to $f(x)$ if and only if $x \leq 0$.
  }
\end{exercise}
\begin{solution}
  \enum{
    \item \(g(x) = 1/(1+x^2)\). We already have that the Taylor series for this is \(\sum^\infty_{n=0}(-1)^n x^2n\), and that it converges to \(g(x)\) for \(|x| < 1\), but it does not converge at all at \(\pm 1\).
    \item Let \(a(x)\) be the counterexample function introduced at the end of this section. Then set \(h(x) = \sin(x) + a(x)\); since the Taylor series of \(a(x)\) is identically 0, \(h(x)\) has the same Taylor series as \(\sin(x)\).
    \item \[f(x) = \begin{cases}
        0 & x \leq 0 \\
        e^{-1/x^2} & x > 0
    \end{cases}\]
    has Taylor series identically 0.
  }
\end{solution}

\begin{exercise}
  Here is a weaker form of Lagrange's Remainder Theorem whose proof is arguably more illuminating than the one for the stronger result.
  \enum {
  \item First establish a lemma: If $g$ and $h$ are differentiable on $[0, x]$ with $g(0)=h(0)$ and $g^{\prime}(t) \leq h^{\prime}(t)$ for all $t \in[0, x]$, then $g(t) \leq h(t)$ for all $t \in[0, x] .$
  \item Let $f, S_{N}$, and $E_{N}$ be as Theorem 6.6.3, and take $0<x<R$. If $\left|f^{(N+1)}(t)\right| \leq M$ for all $t \in[0, x]$, show
    $$
    \left|E_{N}(x)\right| \leq \frac{M x^{N+1}}{(N+1) !}
    $$
  }
\end{exercise}
\begin{solution}
\enum{
    \item Let \(e(t) = h(t) - g(t)\). If \(g(t) > h(t)\) for some \(t \in [0, x]\) then we could apply the Mean Value Theorem on \(e(t)\) between \(0\) and \(t\) to find \(c \in (0, t) \subseteq [0, x]\) with \(e'(c) = h'(t) - g'(t) < 0\), a contradiction since \(h'(t) \geq g'(t)\).
    \item Since \(S_N^{(N+1)} = 0\), \(f^{(N+1)}(t) = E^{(N+1)}(t)\). We then have \(\abs{E_N^{(N+1)}(t)} \leq E_N^{(N+1)}\leq M\), and by repeated application of the lemma in part (a) we have \(E_N(x) \leq \frac{Mx^{N+1}}{(N+1)!}\). A similar argument holds for \(E_N(x) \geq -\frac{Mx^{N+1}}{(N+1)!}\), and we can combine these succiently as
    \[ \left|E_{N}(x)\right| \leq \frac{M x^{N+1}}{(N+1) !}\]
}
\end{solution}

\begin{exercise}[Cauchy's Remainder Theorem]
  Let $f$ be differentiable $N+1$ times on $(-R, R)$. For each $a \in(-R, R)$, let $S_{N}(x, a)$ be the partial sum of the Taylor series for $f$ centered at $a$; in other words, define
  $$
  S_{N}(x, a)=\sum_{n=0}^{N} c_{n}(x-a)^{n} \quad \text { where } \quad c_{n}=\frac{f^{(n)}(a)}{n !} .
  $$
  Let $E_{N}(x, a)=f(x)-S_{N}(x, a) .$ Now fix $x \neq 0$ in $(-R, R)$ and consider $E_{N}(x, a)$ as a function of $a$.
  \enum {
  \item Find $E_{N}(x, x)$.
  \item Explain why $E_{N}(x, a)$ is differentiable with respect to $a$, and show
    $$
    E_{N}^{\prime}(x, a)=\frac{-f^{(N+1)}(a)}{N !}(x-a)^{N} .
    $$
  \item Show
    $$
    E_{N}(x)=E_{N}(x, 0)=\frac{f^{(N+1)}(c)}{N !}(x-c)^{N} x
    $$
    for some $c$ between 0 and $x$. This is Cauchy's form of the remainder for Taylor series centered at the origin.
  }
\end{exercise}
\begin{solution}
\enum{
    \item \[E_N(x,x) = f(x) - S_N(x,x) = f(x) - c_0 = f(x) - f(x) = 0\]
    \item \[\begin{aligned}E_N'(x,a) &= -S_N'(x,a) = \sum^N_{n=1} \frac{f^{(n)}(a)}{(n-1)!} (x-a)^{n-1} - \sum^N_{n=0}\frac{f^{(n+1)}(a)}{n!} (x-a)^n \\
    &=\sum^{N-1}_{n=0} \frac{f^{(n+1)}(a)}{(n)!} (x-a)^{n} - \sum^N_{n=0}\frac{f^{(n+1)}(a)}{n!} (x-a)^n= \frac{-f^{(N+1)}(a)}{N!}(x-a)^{N}
    \end{aligned}\]
    \item By the Mean Value Theorem
    \[\frac{E_N(x,x) - E_N(x,0)}{x} = E'_N(x,c)\]
    for some \(c \in (0,x)\). Plugging in \(E_n(x,x) = 0\) and the expression for \(E_N'\) derived in part \((b)\) leaves us with the desired result.
}
\end{solution}

\begin{exercise}
  Consider $f(x)=1 / \sqrt{1-x}$.
  \enum {
  \item Generate the Taylor series for $f$ centered at zero, and use Lagrange's Remainder Theorem to show the series converges to $f$ on $[0,1 / 2]$. (The case $x<1 / 2$ is more straightforward while $x=1 / 2$ requires some extra care.) What happens when we attempt this with $x>1 / 2 ?$
  \item Use Canchy's Remainder Theorem proved in Exercise 6.6.9 to show the series representation for $f$ holds on $[0,1)$.
  }
\end{exercise}
\begin{solution}
  \TODO
\end{solution}
