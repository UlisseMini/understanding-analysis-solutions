\section{Derivatives and the Intermediate Value Property}

\begin{exercise}
  Supply proofs for parts (i) and (ii) of Theorem 5.2.4. (addition and scalar multiplication preserve differentiability)
\end{exercise}
\begin{solution}
  Let $f$ and $g$ be differentiable at $c$. $f + g$ is differentiable at $c$ by using the algebraic limit theorem
  $$
  (f + g)' = \lim_{x \to c} \frac{(f + g)(x) - (f + g)(c)}{x-c} = \lim_{x \to c} \frac{f(x) - f(c)}{x - c} \lim_{x \to c} \frac{g(x) - g(c)}{x - c} = f'(c) + g'(c)
  $$
  Likewise for $k \in \mathbf{R}$ we can apply ALT
  $$
  (kf)' = \lim_{x \to c} \frac{kf(x) - kf(c)}{x-c} = k \lim_{x \to c} \frac{f(x)-f(c)}{x-c} = k f'(c)
  $$
\end{solution}

\begin{exercise}
  Exactly one of the following requests is impossible. Decide which it is, and provide examples for the other three. In each case, let's assume the functions are defined on all of $\mathbf{R}$.
  \enum{
  \item Functions $f$ and $g$ not differentiable at zero but where $f g$ is differentiable at zero.
  \item A function $f$ not differentiable at zero and a function $g$ differentiable at zero where $f g$ is differentiable at zero.
  \item A function $f$ not differentiable at zero and a function $g$ differentiable at zero where $f+g$ is differentiable at zero.
  \item A function $f$ differentiable at zero but not differentiable at any other point.
  }
\end{exercise}
\begin{solution}
  \enum{
  \item Let
    $$
    f(x) = \begin{cases}
      -1 &\text{if } x < 0 \\
      1  &\text{if } x \ge 0 \\
    \end{cases}
    $$
    And $g(x) = -f(x)$. Both $f$ and $g$ are not differentiable at $0$, but $fg = 1$ (constant) is.
  \item If $fg$ and $g$ are differentiable at zero, then $(fg)/g = f$ is differentiable at zero provided the quotient is well defined. \textit{However} if we let $g(x) = 0$ then $fg = 0$ is differentiable at zero regardless of $f$. (Note we must have $g(0) = 0$ otherwise $f = (fg)/g$ would be differentiable at zero)
  \item Impossible, since $f = (f + g) - g$ would be differentiable at zero by the differentiable limit theorem
  \item Thomae's function is a starting point
    $$
    t(x) = \begin{cases}
      0   &\text{if } x = 0 \\
      1/n &\text{if } x = m/n \text{ in lowest terms} \\
      x   &\text{if } x \in \mathbf I
    \end{cases}
    $$
    We have
    $$
    t'(0) = \lim_{x \to 0} t(x)/x
    $$
    This limit doesn't exist, but if we define $f(x) = xt(x)$ then the inside is thomae's function and so
    $$
    f'(0) = \lim_{x \to 0} f(x)/x = \lim_{x \to 0} t(x) = 0
    $$
    is the only place the derivative exists.

  }
\end{solution}

\begin{exercise}
  \enum{
  \item Use Definition 5.2.1 to produce the proper formula for the derivative of $h(x)=1 / x$.
  \item Combine the result in part (a) with the Chain Rule (Theorem 5.2.5) to supply a proof for part (iv) of Theorem 5.2.4.
  \item Supply a direct proof of Theorem 5.2.4 (iv) by algebraically manipulating the difference quotient for $(f / g)$ in a style similar to the proof of Theorem 5.2.4 (iii).
  }
\end{exercise}
\begin{solution}
  \enum{
  \item
    $$h'(x) = \lim_{y\to x} \frac{1/y - 1/x}{y-x} = \lim_{y \to x} \frac{x - y}{xy(y-x)} = \lim_{y \to x} -\frac{1}{xy} = -\frac{1}{x^2}$$
  \item By chain rule $(1/g)'(x) = -g'(x)/g(x)^2$ combined with product rule gives
    $$
    \begin{aligned}
      (f \cdot 1/g)'(x) = f'(x) \cdot \frac{1}{g(x)} + f(x)(1/g)'(x) &= \frac{f'(x)}{g(x)} - f(x)\frac{g'(x)}{g(x)^2} \\
                                                                     &= \frac{f'(x)g(x) - f(x)g'(x)}{g(x)^2}
    \end{aligned}
    $$
  \item
    $$
    (f/g)'(x) = \lim_{y \to x} \frac{(f/g)(y) - (f/g)(x)}{y - x} = \lim_{y \to x} \frac{f(y)g(x) - f(x)g(y)}{g(x)g(y)(y-x)}
    $$
    Now the $g(x)g(y)$ goes to $g(x)^2$, we just need to evaluate the derivatives in the numerator. We do this by adding and subtracting $f(x)g(x)$ similar to the proof of the product rule, then use the functional limit theorem to finish it off
    $$
    \lim_{y \to x} \frac{g(x)(f(y)- f(x)) + f(x)(g(x) - g(y))}{g(x)g(y)(y-x)} = \frac{g(x)f'(x) - f(x)g'(x)}{g(x)^2}
    $$
  }
\end{solution}

\begin{exercise}
  Follow these steps to provide a slightly modified proof of the Chain Rule.
  \enum{
  \item Show that a function $h: A \rightarrow \mathbf{R}$ is differentiable at $a \in A$ if and only if there exists a function $l: A \rightarrow \mathbf{R}$ which is continuous at $a$ and satisfies
    $$
    h(x)-h(a)=l(x)(x-a) \quad \text { for all } x \in A
    $$
  \item Use this criterion for differentiability (in both directions) to prove Theorem 5.2.5.
  }
\end{exercise}
\begin{solution}
  \enum{
  \item First suppose $h$ is differentiable at $a$, then we can define $l(x) = \frac{h(x)-h(a)}{x-a}$ for $x \ne a$ and set $l(a) = h'(a)$. $l$ is continuous at $a$ thus we have shown one direction.

    Now suppose $l : A \to \mathbf{R}$ exists and satisfies $h(x) - h(a) = l(x)(x-a)$, then dividing by $(x-a)$ and taking limits gives $h'(a) = l(a)$.
  \item Let $f$ be differentiable at $a$ and $g$ be differentiable at $f(a)$. we will show $g(f(x))$ is differentiable at $a$ with derivative $g'(f(a))f'(a)$.

    Multiply the top and bottom by $f(y)-f(a)$ to get
    $$
    (g \circ f)'(a) = \lim_{y \to a} \frac{g(f(y)) - g(f(a))}{f(y)-f(a)} \cdot \frac{f(y)-f(a)}{y-a}
    $$
    We're almost done, the right hand side is $f'(a)$ we just need to evaluate the nested limit on the left. Define $l(y) = \frac{g(y) - g(f(a))}{y - f(a)}$ and $l(a) = g'(f(a))$ then we have a product of continuous functions so
    $$
    \lim_{y \to a} l(f(y)) \cdot \frac{f(y)-f(a)}{y-a} = g'(f(a)) \cdot f'(a)
    $$

    \TODO Proof as intended, this is the same as the proof in Theorem 5.2.5.
  }
\end{solution}

\begin{exercise}
  Let $$f_{a}(x)= \begin{cases}x^{a} & \text { if } x>0 \\ 0 & \text { if } x \leq 0\end{cases}$$
  \enum{
  \item For which values of $a$ is $f$ continuous at zero?
  \item For which values of $a$ is $f$ differentiable at zero? In this case, is the derivative function continuous?
  \item For which values of $a$ is $f$ twice-differentiable?
  }
\end{exercise}
\begin{solution}
  \enum{
  \item All $a > 0$, if $a = 0$ we get the step function and $a < 0$ gives an asymptote
  \item Differentiable for all $a > 0$, though the derivative won't be continuous if $a \in (0, 1)$ since then $ax^{a-1}$ has an asymptote at zero while the $\le 0$ branch is still zero.
  \item The first derivative is $ax^{a-1}$ which we need to be differentiable at zero, so $a > 1$. 
  }
\end{solution}

\begin{exercise}
  Let $g$ be defined on an interval $A$, and let $c \in A$.
  \enum{
  \item Explain why $g^{\prime}(c)$ in Definition 5.2.1 could have been given by
    $$
    g^{\prime}(c)=\lim _{h \rightarrow 0} \frac{g(c+h)-g(c)}{h} .
    $$
  \item Assume $A$ is open. If $g$ is differentiable at $c \in A$, show
    $$
    g^{\prime}(c)=\lim _{h \rightarrow 0} \frac{g(c+h)-g(c-h)}{2 h} .
    $$
  }
\end{exercise}
\begin{solution}
  \enum{
  \item This is just a change of variable from the normal definition, set $h = (x - c)$ to get
    $$\lim_{x \to c} \frac{g(x) - g(c)}{x-c} = \lim_{h \to 0} \frac{g(c+h) - g(c)}{h}$$
  \item Some basic algebra
    $$\lim_{h \to 0} \frac{g(c+h) - g(c) + g(c) - g(c-h)}{2h} = \frac 12\left(\lim_{h \to 0} \frac{g(c+h)-g(c)}{h} + \lim_{h \to 0} \frac{g(c) - g(c-h)}{h}\right)$$
    The first term is clearly $g'(c)$ and the second is $g'(c)$ with the substitution $h = c-x$ since
    $$
    g'(c) = \lim_{x \to c} \frac{g(c) - g(x)}{c-x}
    $$
    Thus the whole expression is $g'(c)$.
  }
\end{solution}

\begin{exercise}
  Let
  $$
  g_{a}(x)= \begin{cases}x^{a} \sin (1 / x) & \text { if } x \neq 0 \\ 0 & \text { if } x=0\end{cases}
  $$
  Find a particular (potentially noninteger) value for $a$ so that
  \enum{
  \item $g_{a}$ is differentiable on $\mathbf{R}$ but such that $g_{a}^{\prime}$ is unbounded on $[0,1]$.
  \item $g_{a}$ is differentiable on $\mathbf{R}$ with $g_{a}^{\prime}$ continuous but not differentiable at zero.
  \item $g_{a}$ is differentiable on $\mathbf{R}$ and $g_{a}^{\prime}$ is differentiable on $\mathbf{R}$, but such that $g_{a}^{\prime \prime}$ is not continuous at zero.
  }
\end{exercise}
\begin{solution}
  We need $a>0$ to make $g_a$ continuous at zero, for differentiation notice
  $$
  g_a'(0) = \lim_{x \to 0} \frac{g(x) - g(0)}{x - 0} = \lim_{x \to 0} \frac{x^a\sin(1/x)}{x} = \lim_{x \to 0} x^{a-1}\sin(1/x)
  $$
  Thus for differentiation we need $x^{a-1}\sin(1/x)$ to have a limit at zero. Keep this in mind for the problems.
  Also note
  $$
  \begin{aligned}
    g_a'(x) &= ax^{a-1}\sin(1/x) + x^a\cos(1/x)(-1/x^2) \\
            &= ax^{a-1}\sin(1/x) - x^{a-2}\cos(1/x)
  \end{aligned}
  $$

  \enum{
  \item To get unboundedness we need the $x^{a-2}\cos(1/x)$ term to become unbounded, so pick $a = 1.5$ to satisfy $a > 1$ (differentiable) and $a < 2$ (unbounded derivative)
  \item Pick $a = 2.5$, It's clear that $g_a'(x) = 2.5x^{1.5}\sin(1/x)-x^{0.5}\cos(1/x)$ is continuous at zero, but not differentiable since $x^{0.5}\cos(1/x)$ isn't differentiable at zero and $2.5x^{1.5}\sin(1/x)$ is (if both terms were not differentiable they could cancel eachother out, constant vigilance!).
  \item Pick $a = 3.5$, for all intents and purposes $g_a'$ behaves like $g_{a-2}$ (because the $x^{a-2}\cos(1/x)$ term acts as a bottleneck) meaning $g_a''$ exists, but isn't continuous since we get another $-2$ to $a$ leading to a $x^{-0.5}$ term in $g_a''$.
  }
\end{solution}

\begin{exercise}
  Review the definition of uniform continuity (Definition 4.4.4). Given a differentiable function $f: A \rightarrow \mathbf{R}$, let's say that $f$ is \emph{uniformly differentiable} on $A$ if, given $\epsilon>0$ there exists a $\delta>0$ such that
  $$
  \left|\frac{f(x)-f(y)}{x-y}-f^{\prime}(y)\right|<\epsilon \quad \text { whenever } 0<|x-y|<\delta .
  $$
  \enum{
  \item Is $f(x)=x^{2}$ uniformly differentiable on $\mathbf{R} ?$ How about $g(x)=x^{3} ?$
  \item Show that if a function is uniformly differentiable on an interval $A$, then the derivative must be continuous on $A$.
  \item Is there a theorem analogous to Theorem 4.4.7 for differentiation? Are functions that are differentiable on a closed interval $[a, b]$ necessarily uniformly differentiable?
  }
\end{exercise}
\begin{solution}
  \enum{
  \item We have
    $$
    \left|\frac{x^2 - y^2}{x - y} - 2y\right| = \left|(x + y) - 2y\right| = |x - y| < \delta
    $$
    Thus $\delta = \epsilon$ suffices to show $x^2$ is uniformly differentiable. Now for $x^3$
    $$
    \left|\frac{x^3 - y^3}{x - y} - 3y^2\right| = \left|\frac{(x-y)(x^2 + xy + y^2)}{x-y} - 3y^2\right| = |x^2 + xy - 2y^2|
    $$
    Let $y = (x+h)$ to get
    $$|x^2 + x(x+h) - 2(x+h)^2| = |x^2 + x^2 xh - 2x^2 - 4xh - 2h^2| = |3xh + 2h^2|$$
    Fix $0 < h < \delta$, since $x$ can be as big as we want we can make $|3xh + 2h^2| > \epsilon$.
    As no fixed $\delta$ works $x^3$ is not uniformly differentiable.

  \item
    Consider the counterexample $f(x) = x^2\sin(1/x)$ over $[0,1]$ (where $f(0) = 0$).
    $f$ is differentiable over $[0,1]$ but not uniformly differentiable.

    Intuitively this is because I can find $x_n, y_n$ such that the slope between them becomes unbounded, but the derivative $f'$ must stay bounded. To be exact set
    $$
    x_n = \frac{1}{2\pi n + \pi/2}, \quad y_n = \frac{1}{2\pi n}
    $$
    then
    $$
    \begin{aligned}
      \left|\frac{f(x_n) - f(y_n)}{x_n - y_n} - f'(x_n)\right|
      &= \left|\frac{1}{x_n - y_n} - f'(x_n)\right| \\
      &= \left|\frac{(2\pi n)(2\pi n + \pi/2)}{\pi/2} - f'(x_n)\right| \\
      &= \left|4n(2\pi n + \pi/2) - f'(x_n)\right|
    \end{aligned}
    $$
    Now since $f'(x_n) = 2x\sin(1/x) - \cos(1/x)$ is bounded I can defeat any $\delta$ by picking $n$ large enough so that
    $$
    |x_n - y_n| < \delta \quad\text{and}\quad \left|\frac{f(x_n) - f(y_n)}{x_n - y_n} - f'(x_n)\right| \ge \epsilon
    $$
    Thus $f$ is not uniformly differentiable.

    If you try to apply the same proof as for uniform continuity you get stuck at the triangle inequality.
  }
\end{solution}

\begin{exercise}
  Decide whether each conjecture is true or false. Provide an argument for those that are true and a counterexample for each one that is false.
  \enum{
  \item If $f^{\prime}$ exists on an interval and is not constant, then $f^{\prime}$ must take on some irrational values.
  \item If $f^{\prime}$ exists on an open interval and there is some point $c$ where $f^{\prime}(c)>0$, then there exists a $\delta$-neighborhood $V_{\delta}(c)$ around $c$ in which $f^{\prime}(x)>0$ for all $x \in V_{\delta}(c)$.
  \item If $f$ is differentiable on an interval containing zero and if $\lim _{x \rightarrow 0} f^{\prime}(x)=L$, then it must be that $L=f^{\prime}(0)$.
  }
\end{exercise}
\begin{solution}
  \enum{
  \item If $f'$ is not constant there exist $x,y$ with $f'(x) < f'(y)$, since derivatives obey the intermediate value proper (Theorem 5.2.7) $f'$ takes on the value of every irrational number in $(f'(x), f'(y))$.
  \item True if $f'$ is continuous, False in general. Let $f(x) = x^2\sin(1/x) + x/2$ so that
    $$
    f'(x) = 2x\sin(1/x) - \cos(1/x) + 1/2
    $$
    Notice how $f'$ alternates between positive and negative for small $x$. We have
    $$
    \lim_{x \to 0} \frac{x^2\sin(1/x) - 0}{x - 0} = \lim_{x \to 0} x\sin(1/x) = 0
    $$
    Thus $f'(0) = 1/2$, pick any $\delta$ and I can find $x \in V_\delta(0)$ with $f'(x) \le 0$.
    To be explicit define $x_n = 1/(2\pi n)$ so that $f'(x_n) = -1/2$ then pick $n$ large enough so $x_n \in V_\delta(0)$.
  \item This isn't saying derivatives are continuous, it's saying \emph{if the limit exists} then $L = f'(0)$.
    Attempting to use $x^2\sin(1/x)$ again as a counterexample doesn't work as the limit doesn't exist.
    And modifying it into $x^{2.5}\sin(1/x)$ (so the limit exists) makes $L = f'(0)$.

    Pick $\delta > 0$, By IVP for any $y \in (f'(0), f'(\delta))$ I can find $x \in (0, \delta)$ with $f'(x) = y$.
    Thus $L \ne f'(0)$ is impossible as I can always find values of $x \in (-\delta,\delta)$ such that $|f'(x) - f'(0)|$ is as small as I want.
  }
\end{solution}

\begin{exercise}
  Recall that a function $f:(a, b) \rightarrow \mathbf{R}$ is increasing on $(a, b)$ if $f(x) \leq f(y)$ whenever $x<y$ in $(a, b)$. A familiar mantra from calculus is that a differentiable function is increasing if its derivative is positive, but this statement requires some sharpening in order to be completely accurate.
  Show that the function
  $$
  g(x)= \begin{cases}x / 2+x^{2} \sin (1 / x) & \text { if } x \neq 0 \\ 0 & \text { if } x=0\end{cases}
  $$
  is differentiable on $\mathbf{R}$ and satisfies $g^{\prime}(0)>0$. Now, prove that $g$ is not increasing over any open interval containing 0 .

  In the next section we will see that $f$ is indeed increasing on $(a, b)$ if and only if $f^{\prime}(x) \geq 0$ for all $x \in(a, b)$.
\end{exercise}
\begin{solution}
  \TODO
\end{solution}

\begin{exercise}
  Assume that $g$ is differentiable on $[a, b]$ and satisfies $g^{\prime}(a)<$ $0<g^{\prime}(b)$.
  \enum{
  \item Show that there exists a point $x \in(a, b)$ where $g(a)>g(x)$, and a point $y \in(a, b)$ where $g(y)<g(b)$.
  \item Now complete the proof of Darboux's Theorem started earlier.
  }
\end{exercise}
\begin{solution}
  \TODO
\end{solution}

\begin{exercise}[Inverse functions]
  If $f:[a, b] \rightarrow \mathbf{R}$ is one-to-one, then there exists an inverse function $f^{-1}$ defined on the range of $f$ given by $f^{-1}(y)=$ $x$ where $y=f(x)$. In Exercise 4.5.8 we saw that if $f$ is continuous on $[a, b]$, then $f^{-1}$ is continuous on its domain. Let's add the assumption that $f$ is differentiable on $[a, b]$ with $f^{\prime}(x) \neq 0$ for all $x \in[a, b]$. Show $f^{-1}$ is differentiable with
  $$
  \left(f^{-1}\right)^{\prime}(y)=\frac{1}{f^{\prime}(x)} \quad \text { where } y=f(x) .
  $$
\end{exercise}
\begin{solution}
  \TODO
\end{solution}
